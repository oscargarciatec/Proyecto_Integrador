{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéì Maestr√≠a en Inteligencia Artificial Aplicada\n",
        "\n",
        "![tec.webp](data:image/webp;base64,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)\n",
        "\n",
        "## üñºÔ∏è **Proyecto Integrador**\n",
        "\n",
        "### üë®‚Äçüè´ **Profesores**\n",
        "\n",
        "- **Profesor Titular:** Dra. Grettel Barcel√≥ Alonso\n",
        "- **Asesor:** Dr. Horacio Mart√≠nez Alfaro\n",
        "\n",
        "## **<font color=\"#895cf9\">Avance 2. Ingenier√≠a de caracter√≠sticas</font>**\n",
        "### **Spin Compass**\n",
        "\n",
        "### üìå **Detalles de la Actividad**\n",
        "\n",
        "- **C√≥digo:** 10.5 Google Colab\n",
        "- **T√≠tulo:** Avance 2. Ingenier√≠a de caracter√≠sticas\n",
        "- **Fecha de entrega:** 8 de feb de 2026 23:59\n",
        "- **Formato de entrega:** Notebook (.ipynb) + Informe\n",
        "- **Modalidad:** Equipo\n",
        "\n",
        "## üë• **Equipo 5**\n",
        "\n",
        "### üöÄ **Nuestro Equipo**\n",
        "\n",
        "  - Tania Alicia Caballero Saavedra - A01795957\n",
        "  - Oscar Enrique Garc√≠a Garc√≠a - A01016093\n",
        "  - Dante Rosas Fragoso ‚Äì A01795850\n",
        "\n"
      ],
      "metadata": {
        "id": "WwrZsndcnViA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05YOvfm6h-Dw",
        "outputId": "369b4019-08f1-4fe9-b939-17f2b20fa344"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.3.7)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.1)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script de Chunking Sem√°ntico Avanzado\n",
        "Integra l√≥gica original de limpieza con nuevos algoritmos:\n",
        "1. Max-Min Semantic Chunking\n",
        "2. Growing Window Semantic Chunking\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Configuraci√≥n y Constantes ---\n",
        "\n",
        "try:\n",
        "    drive.mount(\"/content/drive\")\n",
        "    # Ruta espec√≠fica del usuario original\n",
        "    DRIVE_PATH = Path(\"/content/drive/MyDrive/Colab_Notebooks/MNA/Proyecto_Integrador-main\")\n",
        "\n",
        "    if DRIVE_PATH.exists():\n",
        "        PROJECT_ROOT = DRIVE_PATH\n",
        "        print(f\"Ruta de Drive encontrada: {PROJECT_ROOT}\")\n",
        "    else:\n",
        "        # Si la carpeta espec√≠fica no existe en tu Drive, usamos una local\n",
        "        print(\"La ruta espec√≠fica no se encontr√≥ en Drive. Usando entorno local.\")\n",
        "        PROJECT_ROOT = Path(\"/content/proyecto_integrador\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"No se pudo montar Drive ({e}). Usando entorno local.\")\n",
        "    PROJECT_ROOT = Path(\"/content/proyecto_integrador\")\n",
        "\n",
        "# Definimos y creamos la ruta de datos raw si no existe\n",
        "RAW_DATA_PATH = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "RAW_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Los archivos se buscar√°n en: {RAW_DATA_PATH}\")\n",
        "print(\"NOTA: Si no tienes los archivos ah√≠, s√∫belos manualmente a esa carpeta en el panel de la izquierda.\")\n",
        "\n",
        "# Configuraci√≥n de Modelos\n",
        "TOKENIZER_MODEL = \"cl100k_base\"  # Para conteo de tokens\n",
        "EMBEDDING_MODEL_NAME = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "# Inicializaci√≥n de Modelos\n",
        "encoder = tiktoken.get_encoding(TOKENIZER_MODEL)\n",
        "print(f\"Cargando modelo de embeddings: {EMBEDDING_MODEL_NAME}...\")\n",
        "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681,
          "referenced_widgets": [
            "43a0139812e647bb859505bdf3576ac9",
            "b4203de999dd4084bc4835ac931b3ab1",
            "2445c9918ced4f8da7505488b63c09b1",
            "f8bde071f2ff41d8bb9bf7ca01b93f71",
            "8702536e1b7a42bda9c2ca9b8b97993e",
            "e53c8216d2144704b28750fa27278682",
            "784afbbd5c0d451eb43b2882e1c3a8f9",
            "5fe576d2c97147c5a8f0c9072e4e9c7e",
            "3abcc4a5fc474682832e81d765a2d1f4",
            "6e05778782624105b171c290b51eb36d",
            "02b3fcf815964320ab94a5e8f8b0e54b",
            "9efdc5369f324bc6bc8b45c0e9ba244e",
            "75a4597af037405eaa5efe55ce56cd9a",
            "7dbcfd5615cb4427888390f0f52ecafb",
            "235bb251f5b5431eafbdeb3a440c3f02",
            "5026a8c476fb4aab8820fd381526ef57",
            "2b128d1d362e4f9ca343f53b9b85c995",
            "95091a49dd9f4cee9e933e5afb0e8be9",
            "7bd46ddae07d4db7937ba71b4b26f1bb",
            "f0916f21ba854390aa3b630efc3a42e3",
            "e66bf614eaa348a48c18e5f62264b90c",
            "232cd3be53e547dd9cd3e2cb6a2da52a",
            "64de918321cb4fbaa62280e161ac5680",
            "6bde8efc562842d0bd2fbacda35c29ae",
            "f437625dd37040af998bdf3e4c2ef89c",
            "2da5bc35a470468a8ffebc14f16bf5eb",
            "68d2ff30c2cf44609f8c4359c5c38ca9",
            "24b8eed3db684ec38db35ed9b3742caa",
            "870fc26957f4451ea04940ddc0f91804",
            "f18f307ad89041bfa1f845f2e444f9cf",
            "31137e828afe4e709b97e19fba7deaba",
            "1099adbe18ef486880331948ddd79a91",
            "708fcb5ef6d94e0b9105596722690946",
            "a744a4e392204edf8a779579582b13d1",
            "8676c9dd32c04832b7d698df7e49a7fb",
            "d1b23e6e33f540569f6447cd1942c172",
            "d71d9d905ad24979b9425f0e965cd03e",
            "f6ada1ed0b2949f18d22be4762b040ef",
            "8771a6395d22412595ad49416504a107",
            "c7cbfadd9384489c979a64ddbdc57ee5",
            "f0f6a7e6296c4d45830dcd29dfe355ee",
            "3dbd14c4ae744f4896a7cfce826e83c0",
            "3ada91aedb4e4b8ebce8d3d07deee371",
            "7418e5564b8747ddb2c08e4b761e6701",
            "e853aa2b07474cbab3ca7634517222d5",
            "998b34c3109440d58806c8e501336cfa",
            "684edad1bad345549f17b80b539e69ce",
            "aa6aab6b86eb40648b537b3c843c1a10",
            "d0143131c68e4c7c8797cc5fd67d8d0c",
            "0e3320c0f02c4d94a28010e8d099da3f",
            "5c0fa5b0fe9441229aa065f911604b37",
            "b920286951ba4e07970cb914e0235d5c",
            "6c056ccdbc9e449eba30924ee8c06434",
            "a7948f5a2a3e488b985be7b6f09e1f09",
            "7509dc11144f4c3bbeb8b867a8cafec3",
            "2dc53aa54cde4d2f8796652c9a71eb5f",
            "e61cc34eff07418686a1dbe0c19c56d5",
            "9b3d4a9aec8841039cc6e4364d020515",
            "05ad0768b8924b859700b3ea2a273ca0",
            "dded183ad69c4245a4015bbcbe82aaef",
            "7b4bf6a9c7e7425bbb93b98de72c12da",
            "03626724d7ea4bc8b89dfdcfa07488a5",
            "3bef31df3214490b84058e007b2de8ea",
            "7f6ebe894ff04f3f9861db51480639c3",
            "f461cb2c256846f68b6021d3aec0a06b",
            "f8f4267b0b8641e282bf095dd52f734b",
            "37b9d05d3da4470890c817cb41a4dd26",
            "681ea9048fea4db98a527fd4247ca33a",
            "a764f31315f94b85a28546be57b2efe0",
            "c6921ee87afb4a06a0acfb763d5541f1",
            "609219d3fa6d47c480a0a867efa3885a",
            "bcf7bae32dcb47bab07b4b2220d0179c",
            "25a6e49af6ff43a3b7c2c94a3e515203",
            "f0724eb5b86b4d2ba838df9a6ece2a33",
            "814058624e3e4dc59bba333b0ebb9ec7",
            "2f5be550119542f9acf49c41fa4fad48",
            "7abca6023ad84b148cacb2990f38b661",
            "b5b5584721e6420b81516683983de8eb",
            "9b488450841a4d099fdac9b90f1aaa60",
            "04743249970f4fdea7523cc156c816ce",
            "300722fe954d4556bda6c93209da3093",
            "9b4a50e56a2b4177a38bd30ef40b7e0a",
            "a6d97afcaf7b4001b933ab0c506cb191",
            "33e5716de161436faf63d921fba98cf7",
            "e4a32952fb154b9d8dd978c5b2c9cceb",
            "2a35b5a5c5f24980aea9f9c9bd3ef4aa",
            "0b2ef23e756b4e8890ba937ac5d7bc24",
            "bc32424343b34636b0385a2a8ff843e5",
            "3c2835e0345e49c2b0e4fa26885dd618",
            "6b32992881164998a29ff1b12b6bfe26",
            "449d1817fc25438aa12af0e693902578",
            "1bb91d709efe48d1a9cfe019fc7244bf",
            "3ae36e7827f44750abbc07be41e46a27",
            "1cef843d7db849d1b1ec6d14ff7d9006",
            "690d831de4a54d7ca0b193a051e2fd6a",
            "a6b2b37012bc46b19c76daa204fa6770",
            "fc42bbc33e8c42afa8f7bba94a9894f9",
            "feca2593fd4c4fd08e36c0d10397e373",
            "5cecbfe681504eaab89db58eea030161",
            "e3a74fe7e86240a19c03d66cd22340c1",
            "98b9e2fff50c41349c2a6a8d1138c51f",
            "9030e9a8bc894616aea1c37a6c1a0c2c",
            "c2eafb9728f34efe93d5034d99c3bb24",
            "cc0df2507eb44fdab4e55af3b68f0389",
            "15a50c1781d94b11b9d5e22a3177eb2b",
            "fbde3a92b3a140cda9f6c0eece5ba359",
            "b797fb559798432aa407f3a03d589617",
            "fa29d6ad5de848d9afe34fb4747e9134",
            "85809cac43444dd085e2278b9759f855",
            "7f9b17b9baf14785a1ac4fe2d5c2dab0",
            "5fb78abd95be4e808fa11da69fefbd8d",
            "4fec71d475a04a2995a405f36a124943",
            "f4bbc2415d0c4bd08177c265669d480a",
            "79b0e74db06a4caaa4e10c49371391af",
            "4c02d94637374fbe802c6af31c8497d7",
            "042c0dd31d7049aaa4933ceedbf6b32b",
            "e598ac5265cb4ae8a35dcc9ef0fc6957",
            "ab5ea3cae1f645bcabc8e830483ffcaf",
            "206abb1974f84f408f4d4257c896fcda",
            "2313349a50464845a2757e4ad6c1c4ca",
            "87422a06cb49417db3645a5a47ee4b24"
          ]
        },
        "id": "bVUS5SqihhSR",
        "outputId": "1908d977-10a1-42d5-c88b-5677854f4d68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "La ruta espec√≠fica no se encontr√≥ en Drive. Usando entorno local.\n",
            "Los archivos se buscar√°n en: /content/proyecto_integrador/data/raw\n",
            "NOTA: Si no tienes los archivos ah√≠, s√∫belos manualmente a esa carpeta en el panel de la izquierda.\n",
            "Cargando modelo de embeddings: paraphrase-multilingual-MiniLM-L12-v2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43a0139812e647bb859505bdf3576ac9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9efdc5369f324bc6bc8b45c0e9ba244e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64de918321cb4fbaa62280e161ac5680"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a744a4e392204edf8a779579582b13d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e853aa2b07474cbab3ca7634517222d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dc53aa54cde4d2f8796652c9a71eb5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37b9d05d3da4470890c817cb41a4dd26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/526 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b5584721e6420b81516683983de8eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c2835e0345e49c2b0e4fa26885dd618"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3a74fe7e86240a19c03d66cd22340c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fb78abd95be4e808fa11da69fefbd8d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Funciones de Carga y Limpieza ---\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"Extrae todo el texto de un archivo PDF.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "def load_documents(base_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Carga documentos PDF, TXT o MD desde una ruta base.\n",
        "    Retorna un DataFrame con el nombre del archivo, ruta y texto crudo.\n",
        "    \"\"\"\n",
        "    if not base_path.exists():\n",
        "        print(f\"Advertencia: La ruta {base_path} no existe. Creando ruta vac√≠a.\")\n",
        "        base_path.mkdir(parents=True, exist_ok=True)\n",
        "        return pd.DataFrame(columns=[\"file\", \"path\", \"text\"])\n",
        "\n",
        "    docs = []\n",
        "    for path in base_path.rglob(\"*\"):\n",
        "        text = \"\"\n",
        "        try:\n",
        "            if path.suffix.lower() == \".pdf\":\n",
        "                text = extract_text_from_pdf(str(path))\n",
        "            elif path.suffix.lower() in [\".txt\", \".md\"]:\n",
        "                text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if text.strip():  # Solo agregar si hay texto\n",
        "                docs.append({\n",
        "                    \"file\": path.name,\n",
        "                    \"path\": str(path),\n",
        "                    \"text\": text\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error leyendo {path.name}: {e}\")\n",
        "\n",
        "    return pd.DataFrame(docs)\n",
        "\n",
        "\n",
        "class NoiseReducer:\n",
        "    \"\"\"Clase encargada de limpiar ruido com√∫n en documentos corporativos.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.patterns = [\n",
        "            r\"page\\s+\\d+(\\s+of\\s+\\d+)?\",\n",
        "            r\"p√°gina\\s+\\d+(\\s+de\\s+\\d+)?\",\n",
        "            r\"instituto tecnol√≥gico.*\",\n",
        "            r\"tecnol√≥gico de monterrey.*\",\n",
        "            r\"este documento.*confidencial.*\",\n",
        "            r\"Spin\\s+HOJA\\s+\\d+\\s+de\\s+\\d+\",\n",
        "            r\"C√≥digo\\s+ND-TIFS-PEC-\\d+\",\n",
        "            r\"Direcci√≥n Administraci√≥n y Finanzas\",\n",
        "            r\"Versi√≥n:\\s+\\d+\\.\\d+\",\n",
        "            r\"Fecha de creaci√≥n:.*\",\n",
        "            r\"Fecha de modificaci√≥n.*\",\n",
        "            r\"Estatus\\s+Vigente\"\n",
        "        ]\n",
        "\n",
        "    def clean(self, text: str) -> str:\n",
        "        \"\"\"Aplica limpieza de patrones y normalizaci√≥n de espacios.\"\"\"\n",
        "        for p in self.patterns:\n",
        "            text = re.sub(p, \"\", text, flags=re.IGNORECASE)\n",
        "\n",
        "        # Normalizaci√≥n de saltos de l√≠nea\n",
        "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
        "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
        "        return text.strip()\n",
        "\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"Normalizaci√≥n final: colapsa espacios y une l√≠neas rotas.\"\"\"\n",
        "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
        "    text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def split_into_sentences(text: str) -> List[str]:\n",
        "    \"\"\"Divide el texto en oraciones usando puntuaci√≥n b√°sica.\"\"\"\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    return [s.strip() for s in sentences if len(s.strip()) > 5]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cI1wc3odhpWu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implementaci√≥n de los M√©todos\n",
        "\n",
        "1: Max-Min Semantic Chunking\n",
        "Basado en el documento Max‚ÄìMin semantic chunking of documents for RAG application.pdf, este algoritmo decide si agrupar una oraci√≥n bas√°ndose en la similitud m√≠nima dentro del chunk actual y la similitud m√°xima de la nueva oraci√≥n contra el chunk\n",
        "\n",
        "2: Growing Window Semantic Chunking\n",
        "\n",
        "Basado en el documento Optimising retrieval performance in RAG systems... .pdf, este m√©todo compara el embedding del chunk acumulado contra el embedding de las siguientes $m$ oraciones .\n",
        "\n",
        "Par√°metros:Para Max-Min, los autores recomiendan hard_thr=0.6, c=0.9, init_const=1.5.Para Growing Window, los autores probaron configuraciones como $n=6, m=3$ y $n=8, m=4$."
      ],
      "metadata": {
        "id": "XTs8NPZZpYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Nuevos Algoritmos de Chunking ---\n",
        "\n",
        "def get_embeddings(sentences: List[str]):\n",
        "    \"\"\"Wrapper para obtener embeddings de una lista de textos.\"\"\"\n",
        "    return embedding_model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "\n",
        "def sigmoid(x: float) -> float:\n",
        "    \"\"\"Funci√≥n sigmoide auxiliar.\"\"\"\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "\n",
        "def max_min_chunking(\n",
        "    text: str,\n",
        "    hard_thr: float = 0.6,\n",
        "    c: float = 0.9,\n",
        "    init_const: float = 1.5\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Implementaci√≥n del algoritmo Max-Min Semantic Chunking.\n",
        "    Referencia: Kiss et al. (2025)\n",
        "    \"\"\"\n",
        "    sentences = split_into_sentences(text)\n",
        "    if not sentences:\n",
        "        return []\n",
        "\n",
        "    embeddings = get_embeddings(sentences)\n",
        "    chunks = []\n",
        "    current_chunk_indices = []\n",
        "\n",
        "    for k, embedding_k in enumerate(embeddings):\n",
        "        # Inicializaci√≥n del primer chunk\n",
        "        if not current_chunk_indices:\n",
        "            current_chunk_indices.append(k)\n",
        "            continue\n",
        "\n",
        "        # Caso: El chunk actual tiene solo una oraci√≥n\n",
        "        if len(current_chunk_indices) == 1:\n",
        "            prev_idx = current_chunk_indices[0]\n",
        "            sim = util.cos_sim(embeddings[prev_idx], embedding_k).item()\n",
        "\n",
        "            if init_const * sim > hard_thr:\n",
        "                current_chunk_indices.append(k)\n",
        "            else:\n",
        "                chunks.append(\" \".join([sentences[i] for i in current_chunk_indices]))\n",
        "                current_chunk_indices = [k]\n",
        "            continue\n",
        "\n",
        "        # Caso: Chunk con m√∫ltiples oraciones\n",
        "        chunk_embeddings = embeddings[current_chunk_indices]\n",
        "\n",
        "        # Calcular min_sim(C): m√≠nima similitud dentro del chunk\n",
        "        cos_scores = util.cos_sim(chunk_embeddings, chunk_embeddings)\n",
        "        mask = ~np.eye(len(chunk_embeddings), dtype=bool)\n",
        "        min_sim_c = cos_scores[mask].min().item() if mask.any() else 1.0\n",
        "\n",
        "        # Calcular max_sim(sk, C): m√°xima similitud de nueva oraci√≥n con chunk\n",
        "        sims_new = util.cos_sim(embedding_k, chunk_embeddings)\n",
        "        max_sim_sk_c = sims_new.max().item()\n",
        "\n",
        "        # Threshold din√°mico\n",
        "        thr_c = max(c * min_sim_c * sigmoid(len(current_chunk_indices)), hard_thr)\n",
        "\n",
        "        if max_sim_sk_c >= thr_c:\n",
        "            current_chunk_indices.append(k)\n",
        "        else:\n",
        "            chunks.append(\" \".join([sentences[i] for i in current_chunk_indices]))\n",
        "            current_chunk_indices = [k]\n",
        "\n",
        "    # Agregar remanente\n",
        "    if current_chunk_indices:\n",
        "        chunks.append(\" \".join([sentences[i] for i in current_chunk_indices]))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def growing_window_chunking(\n",
        "    text: str,\n",
        "    n: int = 6,\n",
        "    m: int = 3,\n",
        "    threshold: float = 0.5\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Implementaci√≥n del algoritmo Growing Window Semantic Chunking.\n",
        "    Referencia: Moreno-Cediel et al. (2025)\n",
        "    \"\"\"\n",
        "    sentences = split_into_sentences(text)\n",
        "    if not sentences:\n",
        "        return []\n",
        "\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    total_sentences = len(sentences)\n",
        "\n",
        "    # Inicializar con las primeras 'n' oraciones\n",
        "    current_chunk_sents = sentences[i:min(i + n, total_sentences)]\n",
        "    i += len(current_chunk_sents)\n",
        "\n",
        "    while i < total_sentences:\n",
        "        # Obtener las siguientes 'm' oraciones candidatas\n",
        "        next_m_sents = sentences[i:min(i + m, total_sentences)]\n",
        "        if not next_m_sents:\n",
        "            break\n",
        "\n",
        "        # Comparar embedding del chunk acumulado vs. embedding de las siguientes m\n",
        "        emb_current = get_embeddings([\" \".join(current_chunk_sents)])[0]\n",
        "        emb_next = get_embeddings([\" \".join(next_m_sents)])[0]\n",
        "\n",
        "        similarity = util.cos_sim(emb_current, emb_next).item()\n",
        "\n",
        "        if similarity >= threshold:\n",
        "            # Unir (Crecer ventana)\n",
        "            current_chunk_sents.extend(next_m_sents)\n",
        "            i += len(next_m_sents)\n",
        "        else:\n",
        "            # Cortar y reiniciar con las siguientes 'n'\n",
        "            chunks.append(\" \".join(current_chunk_sents))\n",
        "            current_chunk_sents = sentences[i:min(i + n, total_sentences)]\n",
        "            i += len(current_chunk_sents)\n",
        "\n",
        "    if current_chunk_sents:\n",
        "        chunks.append(\" \".join(current_chunk_sents))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9q2JkAiUhx52"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Pipeline Principal de Ejecuci√≥n ---\n",
        "\n",
        "def main():\n",
        "    # A. Cargar Documentos\n",
        "    print(\">>> Cargando documentos...\")\n",
        "    df_docs = load_documents(RAW_DATA_PATH)\n",
        "\n",
        "    if df_docs.empty:\n",
        "        print(\"No se encontraron documentos. Por favor sube archivos a:\", RAW_DATA_PATH)\n",
        "        return\n",
        "\n",
        "    # B. Limpieza\n",
        "    print(\">>> Limpiando texto...\")\n",
        "    reducer = NoiseReducer()\n",
        "    df_docs[\"clean_text\"] = df_docs[\"text\"].apply(reducer.clean)\n",
        "    df_docs[\"clean_text\"] = df_docs[\"clean_text\"].apply(normalize_text)\n",
        "\n",
        "    # C. Aplicar M√©todos de Chunking\n",
        "    print(\">>> Ejecutando Max-Min Semantic Chunking...\")\n",
        "    # Par√°metros recomendados: hard_thr=0.6, c=0.9, init_const=1.5\n",
        "    df_docs[\"max_min_chunks\"] = df_docs[\"clean_text\"].apply(\n",
        "        lambda x: max_min_chunking(x, hard_thr=0.6, c=0.9, init_const=1.5)\n",
        "    )\n",
        "\n",
        "    print(\">>> Ejecutando Growing Window Semantic Chunking...\")\n",
        "    # Par√°metros recomendados: n=6, m=3 (o n=8, m=4)\n",
        "    df_docs[\"growing_window_chunks\"] = df_docs[\"clean_text\"].apply(\n",
        "        lambda x: growing_window_chunking(x, n=6, m=3, threshold=0.5)\n",
        "    )\n",
        "\n",
        "    # D. Resultados y Comparaci√≥n\n",
        "    print(\"\\n>>> Generando reporte de resultados...\")\n",
        "\n",
        "    # Preparar DataFrames para visualizaci√≥n\n",
        "    df_maxmin = df_docs.explode(\"max_min_chunks\")[[\"file\", \"max_min_chunks\"]]\n",
        "    df_maxmin[\"method\"] = \"Max-Min\"\n",
        "    df_maxmin.rename(columns={\"max_min_chunks\": \"chunk_content\"}, inplace=True)\n",
        "\n",
        "    df_growing = df_docs.explode(\"growing_window_chunks\")[[\"file\", \"growing_window_chunks\"]]\n",
        "    df_growing[\"method\"] = \"Growing Window\"\n",
        "    df_growing.rename(columns={\"growing_window_chunks\": \"chunk_content\"}, inplace=True)\n",
        "\n",
        "    # Concatenar y calcular m√©tricas\n",
        "    df_final = pd.concat([df_maxmin, df_growing])\n",
        "    df_final[\"token_count\"] = df_final[\"chunk_content\"].apply(\n",
        "        lambda x: len(encoder.encode(str(x))) if pd.notna(x) else 0\n",
        "    )\n",
        "\n",
        "    # Mostrar estad√≠sticas\n",
        "    stats = df_final.groupby(\"method\")[\"token_count\"].describe()\n",
        "    print(\"\\nEstad√≠sticas de Tokens por M√©todo:\")\n",
        "    print(stats)\n",
        "\n",
        "    print(\"\\nEjemplo de los primeros chunks:\")\n",
        "    print(df_final.head())\n",
        "\n",
        "# Guardar MinMax en su propio CSV\n",
        "    df_maxmin.to_csv(\"resultados_minmax.csv\", index=False)\n",
        "    print(\"\\nArchivo 'resultados_minmax.csv' guardado con √©xito.\")\n",
        "\n",
        "    # Guardar Growing Window en su propio CSV\n",
        "    df_growing.to_csv(\"resultados_growingwindow.csv\", index=False)\n",
        "    print(\"Archivo 'resultados_growingwindow.csv' guardado con √©xito.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "asCWK1VpnN3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2d6348-9323-4297-bfab-0e4446454d7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Cargando documentos...\n",
            ">>> Limpiando texto...\n",
            ">>> Ejecutando Max-Min Semantic Chunking...\n",
            ">>> Ejecutando Growing Window Semantic Chunking...\n",
            "\n",
            ">>> Generando reporte de resultados...\n",
            "\n",
            "Estad√≠sticas de Tokens por M√©todo:\n",
            "                count        mean         std    min     25%    50%     75%  \\\n",
            "method                                                                        \n",
            "Growing Window   21.0  622.857143  875.933747  143.0  285.00  387.0  647.00   \n",
            "Max-Min         168.0   77.452381   58.134864    5.0   33.75   68.5  106.25   \n",
            "\n",
            "                   max  \n",
            "method                  \n",
            "Growing Window  4336.0  \n",
            "Max-Min          412.0  \n",
            "\n",
            "Ejemplo de los primeros chunks:\n",
            "                         file  \\\n",
            "0  politica-gastos-viajes.pdf   \n",
            "0  politica-gastos-viajes.pdf   \n",
            "0  politica-gastos-viajes.pdf   \n",
            "0  politica-gastos-viajes.pdf   \n",
            "0  politica-gastos-viajes.pdf   \n",
            "\n",
            "                                       chunk_content   method  token_count  \n",
            "0  Nomenclatura  Spin_POL_AYF_GA V_02  Pol√≠tica G...  Max-Min          220  \n",
            "0  Autorizaciones  Elabor√≥  Mario  Alberto  Z√∫√±ig...  Max-Min          216  \n",
            "0  Nomenclatura  Spin_POL_AYF_GA V_02  Pol√≠tica G...  Max-Min          106  \n",
            "0  1.4  17/06/2024  Se incluye:  9.10 Todas las r...  Max-Min           36  \n",
            "0  9.11 Todas las solicitudes deber√°n  ser aproba...  Max-Min           22  \n",
            "\n",
            "Archivo 'resultados_minmax.csv' guardado con √©xito.\n",
            "Archivo 'resultados_growingwindow.csv' guardado con √©xito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretaci√≥n de resultados para Max-Min Semantic Chunking\n",
        "\n",
        "El archivo resultados_minmax.csv contiene los segmentos de texto (chunks) generados por el algoritmo Max-Min Semantic Chunking.\n",
        "\n",
        "Interpretaciones, bas√°ndonos en las primeras filas cargadas:\n",
        "\n",
        "1. Estructura de las Columnas\n",
        "file: Indica el documento de origen (ej. politica-gastos-viajes.pdf). Es √∫til para rastrear de d√≥nde vino la informaci√≥n.\n",
        "\n",
        "chunk_content: Es el resultado principal. Muestra el texto que el algoritmo decidi√≥ agrupar. La longitud y el contenido de este texto var√≠an din√°micamente seg√∫n lo que el algoritmo consider√≥ \"sem√°nticamente coherente\".\n",
        "\n",
        "method: Confirma que se us√≥ la t√©cnica \"Max-Min\".\n",
        "\n",
        "2. Interpretaci√≥n de los Resultados (Ejemplos Reales)\n",
        "Analizando las primeras 5 filas del archivo, se observa c√≥mo \"piensa\" el algoritmo:\n",
        "\n",
        "Identificaci√≥n de Estructuras Repetitivas (Filas 0 y 2):\n",
        "\n",
        "Los chunks que comienzan con \"Nomenclatura Spin_POL...\" y terminan con el aviso de \"informaci√≥n INTERNA\" son encabezados o pies de p√°gina que se repiten en el documento original.\n",
        "\n",
        "Interpretaci√≥n: El algoritmo detect√≥ que este bloque de texto tiene una coherencia interna fuerte y lo separ√≥ del resto.\n",
        "\n",
        "Observaci√≥n: Al aparecer id√©ntico en las filas 0 y 2, sugiere que el pre-procesamiento de limpieza podr√≠a mejorarse para eliminar encabezados de p√°gina repetitivos antes de aplicar el chunking, ya que estos pueden generar ruido en las b√∫squedas (RAG).\n",
        "\n",
        "Agrupaci√≥n de Tablas y Metadatos (Fila 1):\n",
        "\n",
        "Este chunk agrupa toda la secci√≥n de \"Autorizaciones\" e \"Historial de versiones\".\n",
        "\n",
        "Interpretaci√≥n: A pesar de ser varias l√≠neas distintas, el algoritmo determin√≥ que todas hablan del mismo tema (control administrativo del documento) y las mantuvo juntas en un solo bloque grande. Esto es correcto sem√°nticamente.\n",
        "\n",
        "Separaci√≥n de Reglas Espec√≠ficas (Filas 3 y 4):\n",
        "\n",
        "Fila 3: \"1.4 17/06/2024 ... 9.10 Todas las reservaciones deber√°n realizarse 14 d√≠as antes.\"\n",
        "\n",
        "Fila 4: \"9.11 Todas las solicitudes deber√°n ser aprobadas por el Jefe Directo.\"\n",
        "\n",
        "Interpretaci√≥n: Aqu√≠ el algoritmo muestra su fortaleza. En lugar de mezclar estas reglas en un p√°rrafo gigante, detect√≥ que la regla 9.10 y la 9.11 son ideas distintas y cre√≥ chunks peque√±os y precisos para cada una.\n",
        "\n",
        "Valor para RAG: Esto es ideal. Si un usuario pregunta \"¬øCon cu√°nto tiempo debo reservar?\", el sistema recuperar√° solo la Fila 3, dando una respuesta precisa sin informaci√≥n irrelevante."
      ],
      "metadata": {
        "id": "BPGkhCNopLWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretaci√≥n de resultados para Growing Window Semantic Chunking\n",
        "El archivo resultados_growingwindow.csv contiene los segmentos de texto (chunks) generados por el algoritmo Growing Window Semantic Chunking.\n",
        "\n",
        "Interpretaciones, bas√°ndonos en las primeras filas cargadas:\n",
        "\n",
        "1. Estructura de las Columnas\n",
        "file: Indica el documento de origen (ej. politica-gastos-viajes.pdf). Es √∫til para rastrear de d√≥nde vino la informaci√≥n.\n",
        "\n",
        "chunk_content: Es el resultado principal. Muestra el texto que el algoritmo decidi√≥ agrupar en una \"ventana\" continua. A diferencia del m√©todo anterior, aqu√≠ la longitud tiende a ser mucho mayor porque el algoritmo busca mantener el contexto unido mientras la similitud sem√°ntica sea alta.\n",
        "\n",
        "method: Confirma que se us√≥ la t√©cnica \"Growing Window\".\n",
        "\n",
        "2. Interpretaci√≥n de los Resultados (Ejemplos Reales)\n",
        "Analizando las primeras filas del archivo, se observa c√≥mo \"piensa\" este algoritmo (enfoque acumulativo):\n",
        "\n",
        "Fusi√≥n de Estructuras Repetitivas y Metadatos (Fila 0):\n",
        "\n",
        "El primer chunk es un bloque masivo (aprox. 2,450 caracteres) que incluye el encabezado inicial, el aviso de confidencialidad, la repetici√≥n id√©ntica de estos elementos en la segunda p√°gina, la secci√≥n de autorizaciones y el historial de versiones.\n",
        "\n",
        "Interpretaci√≥n: El algoritmo funciona comparando la ventana actual con la siguiente oraci√≥n. Al encontrar un encabezado repetido (texto id√©ntico), la similitud sem√°ntica fue m√°xima, por lo que el algoritmo determin√≥ que \"el tema contin√∫a\" y decidi√≥ no cortar, fusionando m√∫ltiples p√°ginas de metadatos en un solo bloque.\n",
        "\n",
        "Observaci√≥n: Esto confirma que Growing Window es muy sensible al \"ruido\" documental. Sin una limpieza previa que elimine encabezados y pies de p√°gina, el algoritmo tiende a generar bloques excesivamente largos que mezclan contenido real con repeticiones estructurales.\n",
        "\n",
        "Agrupaci√≥n de √çndices y Listas (Fila 1):\n",
        "\n",
        "Este chunk agrupa pr√°cticamente todo el √≠ndice del documento (\"1. OBJETIVO... 5.6 Hospedaje\").\n",
        "\n",
        "Interpretaci√≥n: El algoritmo identific√≥ que todas las l√≠neas del √≠ndice comparten una estructura sem√°ntica y gramatical similar (frases cortas nominales). Por tanto, las trat√≥ como una unidad cohesiva.\n",
        "\n",
        "Valor para RAG: Esto es √∫til para preguntas de resumen general (ej. \"¬øQu√© temas aborda este documento?\"), pero menos efectivo para encontrar una secci√≥n espec√≠fica r√°pidamente.\n",
        "\n",
        "Fusi√≥n de Reglas Espec√≠ficas (Incrustadas en la Fila 0):\n",
        "\n",
        "Dentro del bloque gigante de la Fila 0, se encuentran mezcladas las reglas cr√≠ticas: \"9.10 Todas las reservaciones deber√°n realizarse 14 d√≠as antes\" y \"9.11 Todas las solicitudes deber√°n ser aprobadas...\".\n",
        "\n",
        "Interpretaci√≥n: A diferencia de Max-Min, que separ√≥ estas reglas quir√∫rgicamente, Growing Window las \"enterr√≥\" dentro de un contexto amplio de metadatos. El algoritmo prioriz√≥ la continuidad del texto sobre la distinci√≥n de ideas individuales.\n",
        "\n",
        "Valor para RAG: Esto presenta un desaf√≠o para la precisi√≥n. Si un usuario pregunta \"¬øCu√°ndo debo reservar?\", el sistema recuperar√° este bloque enorme lleno de avisos legales y firmas, obligando al modelo de lenguaje a leer mucho texto irrelevante para encontrar la respuesta de una sola l√≠nea.\n",
        "\n",
        "3. Pistas Visuales de Saturaci√≥n (C√≥mo identificar \"Mega-Chunks\")\n",
        "Al inspeccionar el archivo CSV (ya sea en Excel o en texto plano), existen se√±ales visuales claras que confirman que el algoritmo gener√≥ bloques saturados de informaci√≥n:\n",
        "\n",
        "La Ilusi√≥n de la Celda Vac√≠a (en Excel): Si la celda de contenido (ej. B2) parece estar vac√≠a o en blanco, no significa falta de datos.\n",
        "\n",
        "Causa: El algoritmo absorbi√≥ los saltos de l√≠nea (\\n) del documento original. Excel muestra solo la primera l√≠nea visible; si el texto comienza con espacios o saltos, la celda parecer√° vac√≠a aunque contenga miles de caracteres ocultos debajo.\n",
        "\n",
        "La Trampa de las Comillas (en Texto Plano): Al ver el archivo como texto crudo, el bloque comienza con una comilla de apertura (\") y no se cierra hasta pasar m√∫ltiples p√°ginas de texto.\n",
        "\n",
        "Interpretaci√≥n: El formato CSV encierra en comillas cualquier texto que contenga saltos de l√≠nea internos. Si las comillas no se cierran r√°pidamente, indica que todo ese volumen de texto pertenece a una √∫nica fila l√≥gica que no fue segmentada.\n",
        "\n",
        "El Efecto \"D√©j√† Vu\" (Repetici√≥n Interna): Al leer el contenido de un solo chunk, se encuentran frases id√©nticas repetidas (como el encabezado \"Nomenclatura Spin...\") sin que haya una nueva fila de datos.\n",
        "\n",
        "Conclusi√≥n: Esta repetici√≥n interna es la prueba definitiva de que el algoritmo fusion√≥ la P√°gina 1 y la P√°gina 2 en el mismo bloque, ignorando los l√≠mites f√≠sicos del documento debido a su alta similitud sem√°ntica."
      ],
      "metadata": {
        "id": "s1hjc9lH5c7E"
      }
    }
  ]
}
